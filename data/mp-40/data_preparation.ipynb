{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "import time\n",
    "import dotenv\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mp_api.client import MPRester\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from ase.visualize import view\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mp = Path(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Materials Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your materials project API key in a .env file in the same directory as this notebook. The file should look like this:\n",
    "\n",
    "```\n",
    "MP_API_KEY=your_api_key\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "MP_API_KEY = os.getenv(\"MP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Retrieving created_at from the Materials Project API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`created_at` is only available in the `mpr.materials.search`, so we will use this function to retrieve the registration date of the materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MPRester(MP_API_KEY) as mpr:\n",
    "    total_docs = mpr.materials.search(\n",
    "        num_sites=[0, 40],\n",
    "        fields=[\n",
    "            \"material_id\",\n",
    "            \"created_at\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for doc in total_docs:\n",
    "    data.append(\n",
    "        {\n",
    "            \"material_id\": doc.material_id,\n",
    "            \"created_at\": doc.created_at,\n",
    "        }\n",
    "    )\n",
    "df_mp_created_at = pd.DataFrame(data)\n",
    "# remove duplicates\n",
    "df_mp_created_at = df_mp_created_at.drop_duplicates(subset=[\"material_id\"])\n",
    "# save to csv\n",
    "df_mp_created_at.to_csv(dir_mp / \"mp-created-at.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Donwload snapshot with constraints of num_sites <= 40 and energy convex hull <= 0.25 eV and experimental = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MPRester(MP_API_KEY) as mpr:\n",
    "    docs = mpr.summary.search(\n",
    "        num_sites=[0, 40],\n",
    "        energy_above_hull=[0, 0.25],\n",
    "        theoretical=False,\n",
    "        fields=[\n",
    "            \"material_id\",\n",
    "            \"structure\",\n",
    "            \"energy_above_hull\",\n",
    "            \"band_gap\",\n",
    "            \"theoretical\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_gas_list = [\n",
    "    \"H\",\n",
    "    \"He\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"F\",\n",
    "    \"Ne\",\n",
    "    \"Cl\",\n",
    "    \"Ar\",\n",
    "    \"Kr\",\n",
    "    \"Xe\",\n",
    "    \"Rn\",\n",
    "    \"Fr\",\n",
    "    \"Og\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for doc in tqdm(docs):\n",
    "    st = doc.structure\n",
    "    elements = [elmt.symbol for elmt in st.composition.elements]\n",
    "\n",
    "    if len(elements) == 1 and elements[0] in excluded_gas_list:\n",
    "        print(elements)\n",
    "        continue\n",
    "\n",
    "    if max(st.lattice.abc) > 20:\n",
    "        print(st.formula, st.lattice.abc)\n",
    "        continue\n",
    "\n",
    "    row = {\n",
    "        \"material_id\": doc.material_id,\n",
    "        \"energy_above_hull\": doc.energy_above_hull,\n",
    "        \"band_gap\": doc.band_gap,\n",
    "        \"cif\": st.to(fmt=\"cif\"),\n",
    "    }\n",
    "    data.append(row)\n",
    "\n",
    "df_mp_api = pd.DataFrame(data)\n",
    "# remove duplicates\n",
    "df_mp_api = df_mp_api.drop_duplicates(subset=\"material_id\")\n",
    "# shuffle\n",
    "df_mp_api = df_mp_api.sample(frac=1, random_state=42).reset_index()\n",
    "# save to csv\n",
    "df_mp_api.to_csv(dir_mp / \"mp-api.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate properties\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "\n",
    "def calculate_property(data):\n",
    "    st = Structure.from_str(data.cif, fmt=\"cif\")\n",
    "    sg = SpacegroupAnalyzer(st, symprec=0.1)\n",
    "    data[\"composition\"] = st.composition.reduced_composition.alphabetical_formula\n",
    "    data[\"volume\"] = st.volume\n",
    "    data[\"density\"] = st.density\n",
    "    data[\"atomic_density\"] = st.density\n",
    "    data[\"crystal_system\"] = sg.get_crystal_system()\n",
    "    data[\"space_group_symbol\"] = sg.get_space_group_symbol()\n",
    "    data[\"space_group_number\"] = sg.get_space_group_number()\n",
    "    return data\n",
    "\n",
    "\n",
    "df_mp_api = pd.read_csv(dir_mp / \"mp-api.csv\")\n",
    "df_mp_total = df_mp_api.parallel_apply(calculate_property, axis=1)\n",
    "df_mp_total.to_csv(dir_mp / \"mp-total.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Make test set registered after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge created_at\n",
    "df_mp_created_at = pd.read_csv(dir_mp / \"mp-created-at.csv\")\n",
    "df_mp_total = pd.read_csv(dir_mp / \"mp-total.csv\")\n",
    "df_mp_total = pd.merge(df_mp_total, df_mp_created_at, on=\"material_id\")\n",
    "print(len(df_mp_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot according to the year\n",
    "plt.rcParams[\"font.size\"] = 25\n",
    "df_mp_total[\"created_at\"].apply(lambda x: int(x[:4])).value_counts().sort_index().plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"skyblue\",\n",
    "    title=\"Materials Project API\",\n",
    "    figsize=(12, 6),\n",
    "    xlabel=\"Year\",\n",
    "    ylabel=\"Number of Entries\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(date_str):\n",
    "    date_str = date_str.split(\".\")[0]  # Split by \".\" and take the first part\n",
    "    return datetime.datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "df_mp_total[\"created_at_datetime\"] = df_mp_total[\"created_at\"].apply(\n",
    "    convert_to_datetime\n",
    ")\n",
    "\n",
    "cutoff_date = pd.to_datetime(\"2018-08-04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val\n",
    "df_train_val = df_mp_total[df_mp_total[\"created_at_datetime\"] < cutoff_date]\n",
    "num_val = int(len(df_train_val) * 0.1)\n",
    "df_train = df_train_val.iloc[:-num_val]\n",
    "df_val = df_train_val.iloc[-num_val:]\n",
    "# test\n",
    "df_test = df_mp_total[df_mp_total[\"created_at_datetime\"] >= cutoff_date]\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "df_train.to_csv(dir_mp / \"train.csv\", index=False)\n",
    "df_val.to_csv(dir_mp / \"val.csv\", index=False)\n",
    "df_test.to_csv(dir_mp / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "df_train[\"crystal_system\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\", color=sns.color_palette(\"pastel\")[0], ax=axes[0], title=\"Train\"\n",
    ")\n",
    "df_test[\"crystal_system\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\", color=sns.color_palette(\"pastel\")[1], ax=axes[1], title=\"Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! generate_text_prompt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prompts = Path(\"../mp-50/prompts/\")  # TODO: change the path\n",
    "text_files = list(path_prompts.glob(\"*.txt\"))\n",
    "\n",
    "# read and make df\n",
    "prompts = {}\n",
    "for text_file in text_files:\n",
    "    material_id = text_file.stem\n",
    "    with open(text_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        revised_text = re.sub(r\"\\d+\\.\\s\", \"\", text)\n",
    "        text_prompts = revised_text.split(\"\\n\")\n",
    "        prompt = random.choice(text_prompts)  # select one prompt randomly\n",
    "        prompts[material_id] = prompt\n",
    "\n",
    "df_prompts = pd.DataFrame(prompts.items(), columns=[\"material_id\", \"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update trian, test, val\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    df = pd.read_csv(dir_mp / f\"{split}.csv\")\n",
    "    df = pd.merge(df, df_prompts, on=\"material_id\")\n",
    "    df.to_csv(dir_mp / f\"{split}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info lattice matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(dir_mp / \"train.csv\")\n",
    "st_list = [Structure.from_str(cif, fmt=\"cif\") for cif in df_train[\"cif\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_params = np.array([st.lattice.parameters for st in st_list])\n",
    "lattice_params_mean = lattice_params.mean(axis=0)\n",
    "lattice_params_std = lattice_params.std(axis=0)\n",
    "print(lattice_params_mean, lattice_params_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write\n",
    "lattice_params_mean = lattice_params_mean.tolist()\n",
    "lattice_params_std = lattice_params_std.tolist()\n",
    "with open(dir_mp / \"lattice_params.txt\", \"w\") as f:\n",
    "    f.write(f\"mean: {lattice_params_mean}\\n\")\n",
    "    f.write(f\"std: {lattice_params_std}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random split dataset (not time based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(dir_mp / \"train.csv\")\n",
    "df_val = pd.read_csv(dir_mp / \"val.csv\")\n",
    "df_test = pd.read_csv(dir_mp / \"test.csv\")\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train, df_val, df_test])\n",
    "# remove index column\n",
    "df_total = df_total.drop(columns=[\"index\"])\n",
    "# random shuffle\n",
    "df_total = df_total.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# new_split\n",
    "num_train = len(df_train)\n",
    "num_val = len(df_val)\n",
    "\n",
    "new_train = df_total.iloc[:num_train]\n",
    "new_val = df_total.iloc[num_train : num_train + num_val]\n",
    "new_test = df_total.iloc[num_train + num_val :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = dir_mp / \"random_split\"\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "new_train.to_csv(save_dir / \"train.csv\", index=False)\n",
    "new_val.to_csv(save_dir / \"val.csv\", index=False)\n",
    "new_test.to_csv(save_dir / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mineral dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(dir_mp / \"train.csv\", index_col=0)\n",
    "df_val = pd.read_csv(dir_mp / \"val.csv\", index_col=0)\n",
    "df_test = pd.read_csv(dir_mp / \"test.csv\", index_col=0)\n",
    "print(len(df_train), len(df_val), len(df_test))\n",
    "df_total = pd.concat([df_train, df_val, df_test])\n",
    "print(len(df_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mineral = pd.read_csv(dir_mp / \"mineral/mineral.csv\")[[\"material_id\", \"mineral\"]]\n",
    "print(len(df_mineral))\n",
    "# Remove Nan values in mineral column\n",
    "df_mineral = df_mineral.dropna(subset=[\"mineral\"])\n",
    "print(len(df_mineral))\n",
    "# Only keep when the occurence is more than 10\n",
    "df_mineral = df_mineral.groupby(\"mineral\").filter(lambda x: len(x) > 50)\n",
    "print(len(df_mineral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.merge(df_total, df_mineral, on=\"material_id\")\n",
    "print(len(df_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"mineral\"].value_counts().plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Mineral Distribution (occurence > 40)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: train: 6,000 | val = test = total - train\n",
    "df_total = df_total.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "num_train = 6000\n",
    "df_train = df_total.iloc[:num_train]\n",
    "df_val = df_total.iloc[num_train:]\n",
    "df_test = df_val.copy()\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(dir_mp / \"mineral/train.csv\", index=False)\n",
    "df_val.to_csv(dir_mp / \"mineral/val.csv\", index=False)\n",
    "df_test.to_csv(dir_mp / \"mineral/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemeleon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
